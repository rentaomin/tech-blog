<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <style>
      :root {
        --c-bg: #fff;
      }

      html.dark {
        --c-bg: #22272e;
      }

      html,
      body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia('(prefers-color-scheme: dark)').matches
      if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
        document.documentElement.classList.toggle('dark', true)
      }
    </script>
    <title>kafka 集群 Topic 之 Partion日志分段存储原理设计（五） | 架构师之路</title><meta name="description" content="记录并分享分布式系统与大数据处理技术的深入理解与实践经验。">
    <link rel="stylesheet" href="/tech-blog/assets/css/styles.ed2a9738.css">
    <link rel="preload" href="/tech-blog/assets/js/runtime~app.c6f938d5.js" as="script"><link rel="preload" href="/tech-blog/assets/css/styles.ed2a9738.css" as="style"><link rel="preload" href="/tech-blog/assets/js/6484.f9c8e027.js" as="script"><link rel="preload" href="/tech-blog/assets/js/app.a33b066a.js" as="script">
    <link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群节点选举原理实现(三).html.674cf3b9.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群如何实现数据一致性和顺序性原理.html.967ab3ff.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群节点实现通信原理(二).html.e026819b.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群广播事务性能如何保证.html.868a54f0.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_zookeeper-znode数据结构.html.7dc53fb7.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-上传文件请求负载原理分析.html.20a140fb.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-数据分片多节点存储Java实现.html.d3fabeec.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群节点故障剔除、切换、恢复原理.html.90fb58dd.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群生产环境部署示例.html.806adad7.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群节点选举原理实现(二).html.834bba76.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群数据视图一致性原理.html.d88d014d.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群Session会话一致性实现原理.html.6fc2d82b.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper客户端命令行基础操作.html.c02c2dc1.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群原理设计（二）之源码设计示例分析.html.09d842e2.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群Topic之Partion消息可靠性设计（一）.html.3e920641.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-管理节点Controller设计分析.html.6ae7b2c1.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群节点是如何实现通信和数据同步的.html.273d7d87.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群节点实现通信原理(一).html.b8c100bf.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群节点并行处理超大文件数据分片上传和存储原理分析.html.69ddcdaf.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群的数据顺序写入和零拷贝技术设计实现原理.html.2e43e7bc.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群超大文件上传和异步复制如何确定分块大小.html.636a02fa.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-必备基础知识.html.0379bfed.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群的应用场景.html.6ba72ac1.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群对象版本控制介绍.html.5eb38119.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群Topic、消息大小、节点格式上限管控原理.html.43e32357.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群是如何处理客户端请求.html.a52e5354.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper集群节点选举原理实现(一).html.19ae9760.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群节点数量的设计.html.64ed20db.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群启动过程执行了哪些逻辑.html.089746b4.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群原理设计（四）之Controller选举和Partition分配.html.32287030.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群数据写入确认消息机制分析.html.504f1547.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群原理设计(三)之启动原理介绍.html.69e17a06.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群数据分片如何确认完整性和一致性.html.ab6752b8.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群节点数量与Partition副本数量关系原理.html.e0d42882.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群状态监测、故障切换机制原理.html.aa58527f.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-Stream流处理设计概述.html.e4132270.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群Topic之Partion副本同步性能设计（四）.html.7673be38.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群事务日志机制介绍.html.52c5b655.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群安全认证机制的实现.html.faeaa672.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群Topic之Partion数据写入分布原理设计（六）.html.b3400a1e.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-多站点部署_地理容灾和恢复.html.33068d49.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群Topic之Partion分布原理设计（三）.html.5f3b4ca9.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-超大文件优化原理分析.html.795a3c98.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_redis_Redis-基础概念和常用命令介绍.html.8b284840.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群Topic之Partion日志分段存储原理设计（五）.html.22ed59c0.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群复制队列超大文件（100G）如何存储复制.html.2b0a998b.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群Topic之Partion消息可靠性设计（二）.html.f4f75f38.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-是如何拆分数据多节点存储的.html.44030b8e.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群数据备份和数据复制的区别.html.2979d17e.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群Controller节点和Zookeeper集群leader节点有何区别联系.html.d248d673.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-的单机、集群部署安装.html.87a0f586.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群备份或异地复制如何进行网络带宽限速.html.1d782e7c.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群冷备数据如何恢复部署.html.00e37659.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_getting-started.html.270331bd.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群原理设计和实现概述(一).html.68314c51.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群备份全部数据非特定bucket.html.2dddc817.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群架构设计原理概述.html.8403a1ec.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群如何处理生产者和消费者处理消息速率差异问题.html.85fde3af.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-Topic之Zookeeper数据内容介绍.html.3e25269b.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群安全管控实现原理分析.html.2c9dbd49.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_zookeeper集群部署安装.html.7c4e6cb8.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-单机和集群部署模式.html.dae4c525.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-灾难恢复操作与原理分析.html.8b3e5641.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-架构师必备掌握知识点概览.html.ad2223df.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-分布式锁实现机制.html.63ffd0c9.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群生产性能调优业务场景.html.799e7bb4.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_redis_Redis-高级数据结构和模块介绍.html.d680f950.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-学习目标.html.6ab9d7d8.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群元数据之Zookeeper存储介绍.html.be1bf3cf.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-基础知识和架构设计概览.html.21ad5e24.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群部署为什么至少4个节点.html.ad439cd2.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群为什么依赖zookeeper.html.c3c527be.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_getting-started.html.49b13c22.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群数据备份如何进行冷备.html.7898d819.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_getting-started.html.ecf75cf7.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-组件架构师需要掌握哪些要点.html.71fe6dfc.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-跨中心集群为什么采用异步复制而非构建一个超大集群.html.319daec7.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-学习目标.html.c38011a6.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-集群是如何实现异步复制.html.ac5f5b43.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_kafka_Kafka-集群和Zookeeper集群架构设计对比分析.html.1a8f47a9.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_redis_Redis-学习目标计划.html.51b14e92.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_zookeeper_Zookeeper学习目标.html.1adbea6e.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_minio_Minio-无中心节点集群与有中心节点集群优缺点.html.197a8d51.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/blog_redis_getting-started.html.d722ac59.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/geting-started.html.d43754f9.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/index.html.585527d3.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/tag_分布式管理_index.html.e14ac87f.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/tag_缓存中间件_index.html.b16b56bf.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/tag_对象存储_index.html.e6d6d752.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/tag_消息队列_index.html.70b5fea0.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/category_zookeeper_index.html.ea8d8ff0.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/category_kafka_index.html.d21e5901.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/category_minio_index.html.909c2d43.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/category_redis_index.html.d8c0dceb.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/category_index.html.99c05b96.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/timeline_index.html.411f6642.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/article_index.html.e22623f9.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/404.html.06ca67e5.js" as="script"><link rel="prefetch" href="/tech-blog/assets/js/tag_index.html.937bf476.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon"><!--[--><header class="vp-navbar"><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/tech-blog/"><img class="vp-site-logo" src="https://vuejs.press/images/hero.png" alt="架构师之路"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">架构师之路</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/tech-blog/" aria-label="主页"><!---->主页<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tech-blog/article/" aria-label="文章"><!---->文章<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tech-blog/category/" aria-label="分类"><!---->分类<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tech-blog/tag/" aria-label="标签"><!---->标签<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tech-blog/timeline/" aria-label="时间线"><!---->时间线<!----></a></div><!--]--></nav><!--[--><!--]--><button class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar"><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/tech-blog/" aria-label="主页"><!---->主页<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tech-blog/article/" aria-label="文章"><!---->文章<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tech-blog/category/" aria-label="分类"><!---->分类<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tech-blog/tag/" aria-label="标签"><!---->标签<!----></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tech-blog/timeline/" aria-label="时间线"><!---->时间线<!----></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading">kafka 集群 Topic 之 Partion日志分段存储原理设计（五） <!----></p><!----></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><h1 id="kafka-集群-topic-之-partion日志分段存储原理设计-五" tabindex="-1"><a class="header-anchor" href="#kafka-集群-topic-之-partion日志分段存储原理设计-五"><span>kafka 集群 Topic 之 Partion日志分段存储原理设计（五）</span></a></h1><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre class="language-text"><code><span class="line">kafka 的 topic 中 partition 将消息存储在多个日志分段中，配置文件不是只配置了一个日志路径，</span>
<span class="line">那kafka是如何实现分为多个日志分段文件的，并存储写入topic消息内容的？</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>Kafka 通过将消息日志分成多个分段文件（log segments）来管理每个 Partition 的存储。虽然 Kafka 在配置 文件中只指定了一个日志存储路径，但它会在该路径下根据需要自动创建和管理这些分段文件。以下是详细的实现原 理和操作流程。</p><h3 id="_1-配置文件中的日志存储路径" tabindex="-1"><a class="header-anchor" href="#_1-配置文件中的日志存储路径"><span>1. 配置文件中的日志存储路径</span></a></h3><p>在 Kafka 的配置文件（<code>server.properties</code>）中，日志存储路径通常通过以下配置项指定：</p><div class="language-properties line-numbers-mode" data-highlighter="prismjs" data-ext="properties" data-title="properties"><pre class="language-properties"><code><span class="line"><span class="token key attr-name">log.dirs</span><span class="token punctuation">=</span><span class="token value attr-value">/var/lib/kafka/logs</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这个配置项指定了 Kafka 存储日志文件的目录路径。</p><h3 id="_2-日志分段文件的自动管理" tabindex="-1"><a class="header-anchor" href="#_2-日志分段文件的自动管理"><span>2. 日志分段文件的自动管理</span></a></h3><p>Kafka 会在配置的日志存储路径下自动创建和管理日志分段文件。每个分段文件有固定的大小，当一个分段文件 达到指定大小后，Kafka 会自动创建一个新的分段文件来继续写入消息。</p><h4 id="分段文件的命名规则" tabindex="-1"><a class="header-anchor" href="#分段文件的命名规则"><span>分段文件的命名规则</span></a></h4><p>Kafka 通过文件名来管理和区分不同的分段文件。每个分段文件的文件名是该分段内第一个消息的偏移量。例如：</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre class="language-text"><code><span class="line">/var/lib/kafka/logs/my_topic-0/</span>
<span class="line">  - 00000000000000000000.log</span>
<span class="line">  - 00000000000000001000.log</span>
<span class="line">  - 00000000000000002000.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-核心代码示例和流程" tabindex="-1"><a class="header-anchor" href="#_3-核心代码示例和流程"><span>3. 核心代码示例和流程</span></a></h3><h4 id="日志分段管理" tabindex="-1"><a class="header-anchor" href="#日志分段管理"><span>日志分段管理</span></a></h4><p>Kafka 在每个 Partition 的目录下管理多个分段文件。每个分段文件有固定的大小，当一个分段文件写满后， Kafka 会创建一个新的分段文件。</p><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre class="language-java"><code><span class="line"><span class="token comment">// Log.scala</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">Log</span><span class="token punctuation">(</span>val dir<span class="token operator">:</span> <span class="token class-name">File</span><span class="token punctuation">,</span> val config<span class="token operator">:</span> <span class="token class-name">LogConfig</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">    val segments <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LogSegments</span><span class="token punctuation">(</span>dir<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    def <span class="token function">append</span><span class="token punctuation">(</span>records<span class="token operator">:</span> <span class="token class-name">MemoryRecords</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        val segment <span class="token operator">=</span> <span class="token function">maybeRoll</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        segment<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>records<span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">private</span> def <span class="token function">maybeRoll</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">LogSegment</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        val activeSegment <span class="token operator">=</span> segments<span class="token punctuation">.</span>activeSegment</span>
<span class="line">        <span class="token keyword">if</span> <span class="token punctuation">(</span>activeSegment<span class="token punctuation">.</span>size <span class="token operator">&gt;</span> config<span class="token punctuation">.</span>segmentSize<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">            val newSegment <span class="token operator">=</span> <span class="token function">createNewSegment</span><span class="token punctuation">(</span>activeSegment<span class="token punctuation">.</span>baseOffset <span class="token operator">+</span> activeSegment<span class="token punctuation">.</span>size<span class="token punctuation">)</span></span>
<span class="line">            segments<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>newSegment<span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">        segments<span class="token punctuation">.</span>activeSegment</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">private</span> def <span class="token function">createNewSegment</span><span class="token punctuation">(</span>baseOffset<span class="token operator">:</span> <span class="token class-name">Long</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">LogSegment</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        val logFile <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>dir<span class="token punctuation">,</span> s<span class="token string">&quot;$baseOffset.log&quot;</span><span class="token punctuation">)</span></span>
<span class="line">        val indexFile <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>dir<span class="token punctuation">,</span> s<span class="token string">&quot;$baseOffset.index&quot;</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">new</span> <span class="token class-name">LogSegment</span><span class="token punctuation">(</span>baseOffset<span class="token punctuation">,</span> logFile<span class="token punctuation">,</span> indexFile<span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="日志分段文件的写入" tabindex="-1"><a class="header-anchor" href="#日志分段文件的写入"><span>日志分段文件的写入</span></a></h4><p>当生产者向 Kafka 发送消息时，Kafka 会将这些消息写入当前活动的日志分段文件。如果该分段文件已经达到配置 的最大大小，Kafka 会滚动到一个新的分段文件继续写入。</p><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre class="language-java"><code><span class="line"><span class="token comment">// LogSegment.scala</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">LogSegment</span><span class="token punctuation">(</span>val baseOffset<span class="token operator">:</span> <span class="token class-name">Long</span><span class="token punctuation">,</span> val log<span class="token operator">:</span> <span class="token class-name">File</span><span class="token punctuation">,</span> val index<span class="token operator">:</span> <span class="token class-name">File</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">    val logFile <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileChannel</span><span class="token punctuation">(</span>log<span class="token punctuation">)</span></span>
<span class="line">    val indexFile <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IndexChannel</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    def <span class="token function">append</span><span class="token punctuation">(</span>record<span class="token operator">:</span> <span class="token class-name">Record</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        logFile<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span></span>
<span class="line">        indexFile<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>record<span class="token punctuation">.</span>offset<span class="token punctuation">,</span> logFile<span class="token punctuation">.</span>position<span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-配置日志分段的参数" tabindex="-1"><a class="header-anchor" href="#_4-配置日志分段的参数"><span>4. 配置日志分段的参数</span></a></h3><p>Kafka 通过配置文件中的参数来控制日志分段的大小和滚动策略：</p><div class="language-properties line-numbers-mode" data-highlighter="prismjs" data-ext="properties" data-title="properties"><pre class="language-properties"><code><span class="line"><span class="token key attr-name">log.segment.bytes</span><span class="token punctuation">=</span><span class="token value attr-value">1073741824  # 每个分段文件的最大大小，默认1GB</span></span>
<span class="line"><span class="token key attr-name">log.roll.hours</span><span class="token punctuation">=</span><span class="token value attr-value">168            # 日志分段文件的最大滚动时间，默认7天</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>这些参数确保 Kafka 能够有效地管理日志文件，避免单个文件过大影响性能，并确保日志文件按时间滚动。</p><h3 id="_5-日志分段文件的读取" tabindex="-1"><a class="header-anchor" href="#_5-日志分段文件的读取"><span>5. 日志分段文件的读取</span></a></h3><p>Kafka 通过索引文件快速定位消息，然后从相应的日志分段文件中读取消息。</p><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre class="language-java"><code><span class="line"><span class="token comment">// LogSegment.scala</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">LogSegment</span><span class="token punctuation">(</span>val baseOffset<span class="token operator">:</span> <span class="token class-name">Long</span><span class="token punctuation">,</span> val log<span class="token operator">:</span> <span class="token class-name">File</span><span class="token punctuation">,</span> val index<span class="token operator">:</span> <span class="token class-name">File</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">    def <span class="token function">read</span><span class="token punctuation">(</span>offset<span class="token operator">:</span> <span class="token class-name">Long</span><span class="token punctuation">,</span> maxBytes<span class="token operator">:</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">MemoryRecords</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        val position <span class="token operator">=</span> index<span class="token punctuation">.</span><span class="token function">lookup</span><span class="token punctuation">(</span>offset<span class="token punctuation">)</span></span>
<span class="line">        logFile<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>position<span class="token punctuation">,</span> maxBytes<span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_6-消息存储和读取的完整流程" tabindex="-1"><a class="header-anchor" href="#_6-消息存储和读取的完整流程"><span>6. 消息存储和读取的完整流程</span></a></h3><ol><li><strong>生产者发送消息</strong>：生产者将消息发送到 Kafka 的某个 Topic 的某个 Partition。</li><li><strong>写入活动日志分段文件</strong>：Kafka 将消息写入当前活动的日志分段文件。如果该文件已达到最大大小，则滚动到新 的分段文件。</li><li><strong>创建新分段文件</strong>：当活动日志分段文件达到最大大小时，Kafka 会创建新的分段文件继续写入消息。</li><li><strong>读取消息</strong>：消费者根据消息偏移量读取消息，Kafka 使用索引文件快速定位消息在日志分段文件中的位置，然后 从相应的分段文件中读取消息。</li></ol><h3 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h3><ul><li><strong>日志分段管理</strong>：Kafka 在配置的日志存储路径下自动创建和管理日志分段文件。每个分段文件有固定的大小，达到 最大大小后自动滚动到新的分段文件。</li><li><strong>参数配置</strong>：通过配置参数控制日志分段的大小和滚动策略，确保日志文件管理的高效性。</li><li><strong>分段文件写入和读取</strong>：生产者发送消息时写入当前活动的日志分段文件，消费者读取消息时通过索引文件快速定 位并读取相应的分段文件。</li></ul><p>这些机制确保 Kafka 能够高效地存储和管理大量的消息，提供高吞吐量和可靠性。</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 939943844@qq.com">asus</span><!----><!--]--><!--]--></span></div></div></footer><!----><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script src="/tech-blog/assets/js/runtime~app.c6f938d5.js" defer></script><script src="/tech-blog/assets/js/6484.f9c8e027.js" defer></script><script src="/tech-blog/assets/js/app.a33b066a.js" defer></script>
  </body>
</html>
