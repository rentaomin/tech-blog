"use strict";(self.webpackChunkarch_guide=self.webpackChunkarch_guide||[]).push([[1799],{2096:(a,n,s)=>{s.r(n),s.d(n,{comp:()=>l,data:()=>i});var e=s(641);const t=[(0,e.Fv)('<h1 id="kafka-集群-topic-之-partion-分布原理设计-三" tabindex="-1"><a class="header-anchor" href="#kafka-集群-topic-之-partion-分布原理设计-三"><span>kafka 集群 Topic 之 Partion 分布原理设计（三）</span></a></h1><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre class="language-text"><code><span class="line">同一个partition的副本分布在不同节点，是如何实现的，如何确认在哪个节点上创建，partition</span>\n<span class="line">对应的是分段日志文件，如何进行分段设计的，是文件但为什么说是一个有序消息队列，其它partition</span>\n<span class="line">副本节点消息是与哪个节点的partition leader 进行消息同步，性能是如何保证的?</span>\n<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Kafka 集群通过副本机制和跨节点分布来实现高可用性和容错性。以下是详细解释 Kafka 中同一个 Partition 的副本如何分布在不同节点上、如何确认在哪个节点上创建、副本同步机制、分段日志文件设计，以及性能保证的方法。</p><h3 id="_1-同一个-partition-的副本分布在不同节点" tabindex="-1"><a class="header-anchor" href="#_1-同一个-partition-的副本分布在不同节点"><span>1. 同一个 Partition 的副本分布在不同节点</span></a></h3><h4 id="副本分布原理" tabindex="-1"><a class="header-anchor" href="#副本分布原理"><span>副本分布原理</span></a></h4><p>当创建一个 Topic 时，Kafka 会根据配置的副本因子（replication factor）在不同的 Broker 上创建副本。 Kafka 使用 ZooKeeper 进行副本分配和管理。</p><h4 id="创建-topic-和-partition-副本的示例" tabindex="-1"><a class="header-anchor" href="#创建-topic-和-partition-副本的示例"><span>创建 Topic 和 Partition 副本的示例</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="line"><span class="token comment"># 创建一个名为 &quot;my_topic&quot; 的 Topic，具有 3 个分区和 3 个副本</span></span>\n<span class="line">bin/kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--topic</span> my_topic --bootstrap-server localhost:9092 <span class="token parameter variable">--partitions</span> <span class="token number">3</span> </span>\n<span class="line">--replication-factor <span class="token number">3</span></span>\n<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="确认在哪个节点上创建副本" tabindex="-1"><a class="header-anchor" href="#确认在哪个节点上创建副本"><span>确认在哪个节点上创建副本</span></a></h4><p>Kafka Controller 负责管理 Partition 和副本的分配。当创建 Topic 时，Controller 会分配每个 Partition 的副本到不同的 Broker 上，以实现高可用性和负载均衡。</p><h4 id="核心代码示例" tabindex="-1"><a class="header-anchor" href="#核心代码示例"><span>核心代码示例</span></a></h4><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre class="language-java"><code><span class="line"><span class="token comment">// KafkaController.scala</span></span>\n<span class="line"><span class="token keyword">class</span> <span class="token class-name">KafkaController</span><span class="token punctuation">(</span>zooKeeperClient<span class="token operator">:</span> <span class="token class-name">KafkaZkClient</span><span class="token punctuation">,</span> config<span class="token operator">:</span> <span class="token class-name">KafkaConfig</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>\n<span class="line">    def <span class="token function">onPartitionModifications</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>\n<span class="line">        val partitions <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">getAllPartitions</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>\n<span class="line">        partitions<span class="token punctuation">.</span>foreach <span class="token punctuation">{</span> partition <span class="token operator">=</span><span class="token operator">&gt;</span></span>\n<span class="line">            val leaderIsrAndControllerEpoch <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">getLeaderAndIsrForPartition</span><span class="token punctuation">(</span>partition<span class="token punctuation">)</span></span>\n<span class="line">            <span class="token keyword">if</span> <span class="token punctuation">(</span>leaderIsrAndControllerEpoch<span class="token punctuation">.</span>isEmpty<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>\n<span class="line">                <span class="token comment">// 如果没有 Leader，选举新的 Leader</span></span>\n<span class="line">                partitionStateMachine<span class="token punctuation">.</span><span class="token function">handleStateChanges</span><span class="token punctuation">(</span></span>\n<span class="line">                    <span class="token class-name">Set</span><span class="token punctuation">(</span>partition<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token class-name">OnlinePartition</span><span class="token punctuation">,</span> <span class="token class-name">Map</span><span class="token punctuation">.</span>empty</span>\n<span class="line">                <span class="token punctuation">)</span></span>\n<span class="line">            <span class="token punctuation">}</span></span>\n<span class="line">        <span class="token punctuation">}</span></span>\n<span class="line">    <span class="token punctuation">}</span></span>\n<span class="line"><span class="token punctuation">}</span></span>\n<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-partition-和分段日志文件设计" tabindex="-1"><a class="header-anchor" href="#_2-partition-和分段日志文件设计"><span>2. Partition 和分段日志文件设计</span></a></h3><h4 id="partition-的结构" tabindex="-1"><a class="header-anchor" href="#partition-的结构"><span>Partition 的结构</span></a></h4><p>每个 Partition 是一个有序的、不可变的消息队列，内部结构如下：</p><ul><li><strong>日志文件（Log Segment）</strong>：每个 Partition 由多个日志文件组成，每个日志文件存储若干条消息。</li><li><strong>索引文件</strong>：记录消息在日志文件中的偏移量（offset），便于快速查找。</li></ul><h4 id="分段设计" tabindex="-1"><a class="header-anchor" href="#分段设计"><span>分段设计</span></a></h4><p>Kafka 将 Partition 内的消息分段存储，每个分段是一个独立的日志文件。分段的设计有助于高效地管理和 清理日志文件。</p><h4 id="日志文件和索引文件示例" tabindex="-1"><a class="header-anchor" href="#日志文件和索引文件示例"><span>日志文件和索引文件示例</span></a></h4><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre class="language-java"><code><span class="line"><span class="token comment">// Log.scala</span></span>\n<span class="line"><span class="token keyword">class</span> <span class="token class-name">Log</span><span class="token punctuation">(</span>val dir<span class="token operator">:</span> <span class="token class-name">File</span><span class="token punctuation">,</span> val config<span class="token operator">:</span> <span class="token class-name">LogConfig</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>\n<span class="line">    val segments <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LogSegments</span><span class="token punctuation">(</span>dir<span class="token punctuation">)</span></span>\n<span class="line">    </span>\n<span class="line">    def <span class="token function">append</span><span class="token punctuation">(</span>records<span class="token operator">:</span> <span class="token class-name">MemoryRecords</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>\n<span class="line">        val segment <span class="token operator">=</span> segments<span class="token punctuation">.</span>activeSegment</span>\n<span class="line">        segment<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>records<span class="token punctuation">)</span></span>\n<span class="line">    <span class="token punctuation">}</span></span>\n<span class="line">    </span>\n<span class="line">    def <span class="token function">read</span><span class="token punctuation">(</span>offset<span class="token operator">:</span> <span class="token class-name">Long</span><span class="token punctuation">,</span> maxBytes<span class="token operator">:</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">FetchDataInfo</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>\n<span class="line">        val segment <span class="token operator">=</span> segments<span class="token punctuation">.</span><span class="token function">floorSegment</span><span class="token punctuation">(</span>offset<span class="token punctuation">)</span></span>\n<span class="line">        segment<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>offset<span class="token punctuation">,</span> maxBytes<span class="token punctuation">)</span></span>\n<span class="line">    <span class="token punctuation">}</span></span>\n<span class="line"><span class="token punctuation">}</span></span>\n<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-副本同步机制" tabindex="-1"><a class="header-anchor" href="#_3-副本同步机制"><span>3. 副本同步机制</span></a></h3><h4 id="副本同步原理" tabindex="-1"><a class="header-anchor" href="#副本同步原理"><span>副本同步原理</span></a></h4><p>Kafka 使用 Leader-Follower 机制进行副本同步。每个 Partition 的 Leader 负责处理所有的读写请求， Follower 从 Leader 复制数据。</p><ul><li><strong>Leader</strong>：处理所有的读写请求。</li><li><strong>Follower</strong>：从 Leader 复制数据，确保数据一致性。</li></ul><h4 id="副本同步过程" tabindex="-1"><a class="header-anchor" href="#副本同步过程"><span>副本同步过程</span></a></h4><ol><li><strong>Leader 写入消息</strong>：生产者将消息写入 Partition 的 Leader。</li><li><strong>Follower 复制消息</strong>：Follower 从 Leader 复制消息，保持数据一致性。</li><li><strong>ISR 列表</strong>：In-Sync Replica 列表包含所有与 Leader 保持同步的副本。消息只有在被写入到 ISR 列表中的 所有副本后，才认为被成功提交。</li></ol><h4 id="核心代码示例-1" tabindex="-1"><a class="header-anchor" href="#核心代码示例-1"><span>核心代码示例</span></a></h4><div class="language-java line-numbers-mode" data-highlighter="prismjs" data-ext="java" data-title="java"><pre class="language-java"><code><span class="line"><span class="token comment">// ReplicaFetcherThread.scala</span></span>\n<span class="line"><span class="token keyword">class</span> <span class="token class-name">ReplicaFetcherThread</span><span class="token punctuation">(</span>replicaId<span class="token operator">:</span> <span class="token class-name">Int</span><span class="token punctuation">,</span> leaderId<span class="token operator">:</span> <span class="token class-name">Int</span><span class="token punctuation">,</span> partition<span class="token operator">:</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">)</span></span>\n<span class="line"> <span class="token keyword">extends</span> <span class="token class-name">AbstractFetcherThread</span><span class="token punctuation">(</span>replicaId<span class="token punctuation">,</span> leaderId<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>\n<span class="line">    override def <span class="token function">fetch</span><span class="token punctuation">(</span>fetchRequest<span class="token operator">:</span> <span class="token class-name">FetchRequest<span class="token punctuation">.</span>Builder</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Map</span><span class="token punctuation">[</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">FetchDataInfo</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>\n<span class="line">        val fetchResponse <span class="token operator">=</span> leaderBroker<span class="token punctuation">.</span><span class="token function">fetch</span><span class="token punctuation">(</span>fetchRequest<span class="token punctuation">)</span></span>\n<span class="line">        fetchResponse<span class="token punctuation">.</span>data<span class="token punctuation">.</span>asScala<span class="token punctuation">.</span>map <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>tp<span class="token punctuation">,</span> data<span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">&gt;</span></span>\n<span class="line">            partition<span class="token punctuation">.</span>log<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span></span>\n<span class="line">            tp <span class="token operator">-&gt;</span> <span class="token class-name">FetchDataInfo</span><span class="token punctuation">(</span>partition<span class="token punctuation">.</span>log<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>baseOffset<span class="token punctuation">,</span> data<span class="token punctuation">.</span>records<span class="token punctuation">.</span>sizeInBytes<span class="token punctuation">)</span><span class="token punctuation">)</span></span>\n<span class="line">        <span class="token punctuation">}</span><span class="token punctuation">.</span>toMap</span>\n<span class="line">    <span class="token punctuation">}</span></span>\n<span class="line"><span class="token punctuation">}</span></span>\n<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-消息有序性和一致性" tabindex="-1"><a class="header-anchor" href="#_4-消息有序性和一致性"><span>4. 消息有序性和一致性</span></a></h3><h4 id="保证消息有序" tabindex="-1"><a class="header-anchor" href="#保证消息有序"><span>保证消息有序</span></a></h4><ul><li><strong>分区内有序</strong>：在同一个 Partition 内，消息按照追加的顺序存储和消费，保证分区内消息的有序性。</li><li><strong>全局有序</strong>：如果需要全局有序性，可以将所有消息写入到一个 Partition 中，但这会限制并行处理的能力。</li></ul><h4 id="消息一致性" tabindex="-1"><a class="header-anchor" href="#消息一致性"><span>消息一致性</span></a></h4><ul><li><strong>副本一致性</strong>：通过 ISR 列表确保副本的一致性。消息被写入到所有 ISR 副本后才认为被成功提交。</li><li><strong>数据持久化</strong>：Kafka 将消息持久化到磁盘，即使在 Broker 故障时，消息也不会丢失。</li></ul><h3 id="_5-性能保证" tabindex="-1"><a class="header-anchor" href="#_5-性能保证"><span>5. 性能保证</span></a></h3><p>Kafka 通过以下机制保证高性能：</p><h4 id="分区和并行处理" tabindex="-1"><a class="header-anchor" href="#分区和并行处理"><span>分区和并行处理</span></a></h4><ul><li><strong>分区</strong>：将 Topic 分成多个 Partition，提高并行处理能力。</li><li><strong>并行处理</strong>：生产者和消费者可以并行地向不同的 Partition 写入和读取数据。</li></ul><h4 id="高效的存储和索引" tabindex="-1"><a class="header-anchor" href="#高效的存储和索引"><span>高效的存储和索引</span></a></h4><ul><li><strong>日志分段</strong>：将 Partition 内的消息分段存储，便于高效管理和清理。</li><li><strong>索引文件</strong>：通过索引文件快速查找消息，减少磁盘 I/O。</li></ul><h4 id="零拷贝" tabindex="-1"><a class="header-anchor" href="#零拷贝"><span>零拷贝</span></a></h4><ul><li><strong>零拷贝</strong>：Kafka 使用操作系统的零拷贝机制，减少数据在网络和磁盘之间传输的开销，提高性能。</li></ul><h3 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h3><ul><li><p><strong>同一个 Partition 的副本分布在不同节点上</strong>：通过 ZooKeeper 和 Kafka Controller 的管理，实现跨节 点分布，确保高可用性和容错性。</p></li><li><p><strong>Partition 的分段日志文件设计</strong>：每个 Partition 是一个有序的消息队列，通过日志分段和索引文件实现高 效存储和快速查找。</p></li><li><p><strong>副本同步机制</strong>：使用 Leader-Follower 机制，确保副本的一致性和数据的高可用性。</p></li><li><p><strong>消息有序性和一致性</strong>：通过分区内有序和副本一致性机制，确保消息的有序性和一致性。</p></li><li><p><strong>性能保证</strong>：通过分区并行处理、高效存储和零拷贝机制，确保 Kafka 的高性能。</p></li></ul><p>这些设计和机制使 Kafka 成为一个高效、可靠的分布式消息系统。</p>',44)],p={},l=(0,s(6262).A)(p,[["render",function(a,n){return(0,e.uX)(),(0,e.CE)("div",null,t)}]]),i=JSON.parse('{"path":"/blog/kafka/Kafka-%E9%9B%86%E7%BE%A4Topic%E4%B9%8BPartion%E5%88%86%E5%B8%83%E5%8E%9F%E7%90%86%E8%AE%BE%E8%AE%A1%EF%BC%88%E4%B8%89%EF%BC%89.html","title":"kafka 集群 Topic 之 Partion 分布原理设计（三）","lang":"zh-CN","frontmatter":{"date":"2021-07-07T00:00:00.000Z","category":["Kafka"],"tag":["消息队列"],"sticky":true,"excerpt":"<p>Kafka 集群原理设计分析</p>"},"headers":[{"level":3,"title":"1. 同一个 Partition 的副本分布在不同节点","slug":"_1-同一个-partition-的副本分布在不同节点","link":"#_1-同一个-partition-的副本分布在不同节点","children":[]},{"level":3,"title":"2. Partition 和分段日志文件设计","slug":"_2-partition-和分段日志文件设计","link":"#_2-partition-和分段日志文件设计","children":[]},{"level":3,"title":"3. 副本同步机制","slug":"_3-副本同步机制","link":"#_3-副本同步机制","children":[]},{"level":3,"title":"4. 消息有序性和一致性","slug":"_4-消息有序性和一致性","link":"#_4-消息有序性和一致性","children":[]},{"level":3,"title":"5. 性能保证","slug":"_5-性能保证","link":"#_5-性能保证","children":[]},{"level":3,"title":"结论","slug":"结论","link":"#结论","children":[]}],"git":{"updatedTime":1720532327000,"contributors":[{"name":"asus","email":"939943844@qq.com","commits":1}]},"filePathRelative":"blog/kafka/Kafka-集群Topic之Partion分布原理设计（三）.md"}')}}]);